{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce363dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from circuit_extract import visualize_circuit_masks\n",
    "import circuit_extract as ce\n",
    "import inference\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44a1ad41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'circuit_extract' from '/home/cabbagepatch/Code/MI/vast/Mechanistic-Interpretability/circuit_extract.py'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(inference)\n",
    "importlib.reload(train)\n",
    "importlib.reload(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e2f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_config(ds_name: str, lr: float, epochs: int, seed: int=0):\n",
    "    return {\n",
    "        \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        \"seed\": seed,\n",
    "        \"dataset\": ds_name,\n",
    "        \"epochs\": epochs, \n",
    "        \"lr\": lr,\n",
    "        # \"pfrac\": pfrac,\n",
    "    }\n",
    "\n",
    "def circuit_config(ds_name: str, lr: float, cepochs: int, k_w: int, seed: int=0):\n",
    "    return {\n",
    "        \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        \"seed\": seed,\n",
    "        \"dataset\": ds_name,\n",
    "        \"cepochs\": cepochs, \n",
    "        \"lr\": lr,\n",
    "        \"k_w\": k_w,\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879021b",
   "metadata": {},
   "source": [
    "### Train Sparse Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1d1233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 1: Initialize Model ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Phase 1: Initialize Model ---\")\n",
    "inp_shape = (1, 28, 28)\n",
    "model = inference.CNN(nc=1, nf=16, num_classes=10, inp_shape=inp_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a16686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 2: Train Sparse Baseline ---\n",
      "Running on cpu\n",
      "n_params 20432 n_params_wd 20432\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cabbagepatch/miniconda3/envs/new/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n",
      "/home/cabbagepatch/miniconda3/envs/new/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Acc: 0.9515 | Test Acc: 0.9547\n",
      "Epoch 1 | Train Acc: 0.9717 | Test Acc: 0.9733\n",
      "Epoch 2 | Train Acc: 0.9800 | Test Acc: 0.9811\n",
      "Epoch 3 | Train Acc: 0.9075 | Test Acc: 0.9116\n",
      "Epoch 4 | Train Acc: 0.9223 | Test Acc: 0.9238\n",
      "Epoch 5 | Train Acc: 0.9308 | Test Acc: 0.9347\n",
      "Epoch 6 | Train Acc: 0.9388 | Test Acc: 0.9411\n",
      "Epoch 7 | Train Acc: 0.9423 | Test Acc: 0.9442\n",
      "Epoch 8 | Train Acc: 0.9457 | Test Acc: 0.9466\n",
      "Epoch 9 | Train Acc: 0.9430 | Test Acc: 0.9430\n",
      "Epoch 10 | Train Acc: 0.9391 | Test Acc: 0.9419\n",
      "Epoch 11 | Train Acc: 0.9297 | Test Acc: 0.9327\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Phase 2: Train Sparse Baseline ---\")\n",
    "def scheduler(start, end, start_sparsity, target_sparsity, alpha):\n",
    "    def f(epochs):\n",
    "        t = min(max(0, epochs-start), end-start)/ (end-start)\n",
    "        t = t**alpha\n",
    "        return (target_sparsity* t + (1-t) * start_sparsity)\n",
    "    return f\n",
    "\n",
    "sched = scheduler(3, 12, 1, 0.1, 0.5)\n",
    "# sched(0)\n",
    "# for epoch in range(1,12):\n",
    "#     print(sched(epoch+1))\n",
    "\n",
    "cfg = model_config(ds_name='mnist', lr=1e-3, epochs=12)\n",
    "device = cfg['device']\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "train.train_model(\n",
    "    model=model,\n",
    "    lr=cfg['lr'],\n",
    "    b1=0.9, b2=0.999,\n",
    "    # pfrac=cfg['pfrac'],\n",
    "    scheduler = sched, \n",
    "    ds_name=\"mnist-baseline\",\n",
    "    eps=1e-8,\n",
    "    epochs=cfg['epochs'],\n",
    "    device=device,\n",
    "    seed=cfg['seed']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f56c35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "Device count: 0\n",
      "Current device: None\n"
     ]
    }
   ],
   "source": [
    "print(f'CUDA available: {torch.cuda.is_available()}') \n",
    "print(f'Device count: {torch.cuda.device_count()}')\n",
    "print(f'Current device: {torch.cuda.current_device() if torch.cuda.is_available() else None}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7397bc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0999\n"
     ]
    }
   ],
   "source": [
    "non_zero = sum([(p != 0).sum() for p in model.parameters()])\n",
    "total = sum([p.numel() for p in model.parameters()])\n",
    "\n",
    "print(f\"{non_zero/total:.4f}\")\n",
    "\n",
    "# when retaining also retain other ones\n",
    "# scheduler also add (50 percent of training steos then reach sparsity)\n",
    "# iteratively sparsify features after starting from 0 percent sparsty\n",
    "# circuits should not rely on \n",
    "# for every neuron retain some weights\n",
    "# try pretraining on generation\n",
    "#try on more complex datasets, cmnist, cifar10, pacs\n",
    "#maybe try portability\n",
    "#try training on\n",
    "#try the weird loss thing\n",
    "#mistake : apply sigmoid estimator\n",
    "#see this as an angle to improve DG\n",
    "#how to work with circuits that are not end to end // have to use bigger models\n",
    "#ha405 // visual reasoning\n",
    "#how to find neurons/circuits correspoding to sprurious features / circuits\n",
    "#work with different circuits in cross-domain settings\n",
    "#randomization makes network more generalizable\n",
    "#maybe try and find work in compilers?\n",
    "#LLMs ka kaam karo\n",
    "#senior\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5f468",
   "metadata": {},
   "source": [
    "### Extracting circuit for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d15c3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_class_circuit(class_idx: int, model, epochs=9, l0_lambda=0.05, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Extracts and visualizes a circuit for a specific target class (0-9).\n",
    "    \"\"\"\n",
    "    print(f\" Processing Class {class_idx} \")\n",
    "    \n",
    "    ds_name = f\"mnist-class-{class_idx}\"\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    print(f\"Configuration: Device={device}, Lambda={l0_lambda}, Dataset={ds_name}\")\n",
    "\n",
    "    circuit = train.extract_circuit(\n",
    "        model=model,\n",
    "        lr=lr,\n",
    "        b1=0.9, b2=0.999,\n",
    "        ds_name=ds_name,     \n",
    "        eps=1e-8,\n",
    "        epochs=epochs,\n",
    "        device=device,\n",
    "        l0_lambda=l0_lambda,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    print(f\"\\n--- Visualizing Circuit for Class {class_idx} ---\")\n",
    "    \n",
    "    try:\n",
    "        visualize_circuit_masks(circuit) \n",
    "        \n",
    "        import os\n",
    "        if os.path.exists(\"circuit_visualization.png\"):\n",
    "            os.rename(\"circuit_visualization.png\", f\"circuit_viz_class_{class_idx}.png\")\n",
    "            print(f\"Saved visualization to: circuit_viz_class_{class_idx}.png\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Visualization failed: {e}\")\n",
    "\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe59a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing Class 0 \n",
      "Configuration: Device=cpu, Lambda=1000, Dataset=mnist-class-0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating mean activations...\n"
     ]
    }
   ],
   "source": [
    "circuit_1 = run_class_circuit(class_idx=0, model=model, epochs=5,l0_lambda=1000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf8760b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_neurons(circuit: torch.nn.Module):\n",
    "    flattened_masks = []\n",
    "    for mask in circuit.masks:\n",
    "        flattened_masks.append(mask.mask.flatten())\n",
    "    \n",
    "    concatenated = torch.cat(flattened_masks, dim=0)\n",
    "    return torch.nonzero(concatenated > 0).squeeze()\n",
    "\n",
    "def toggle_neurons(circuit: torch.nn.Module, idxs: torch.Tensor):\n",
    "    flattened_masks = []\n",
    "    for mask in circuit.masks:\n",
    "        flattened_masks.append(mask.mask.flatten())\n",
    "\n",
    "    full_vector = torch.cat(flattened_masks, dim=0)\n",
    "\n",
    "    full_vector[idxs] *= -1\n",
    "\n",
    "    start_idx = 0\n",
    "    with torch.no_grad():\n",
    "        for mask in circuit.masks:\n",
    "            numel = mask.mask.numel()\n",
    "            chunk = full_vector[start_idx : start_idx + numel]\n",
    "            mask.mask.copy_(chunk.view(mask.shape))\n",
    "            start_idx += numel\n",
    "\n",
    "def invert_masks(circuit: torch.nn.Module):\n",
    "    with torch.no_grad(): \n",
    "        for mask in circuit.masks:\n",
    "            mask.mask.mul_(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ad6b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_wise_acc(model, loader, classes, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    epsilon = 1e-8\n",
    "    correct = {cls:0 for cls in classes}\n",
    "    total = {cls:epsilon for cls in classes}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X,Y in loader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            logits = model(X)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            \n",
    "            for i,cls in enumerate(classes):\n",
    "\n",
    "                correct[cls] += torch.sum((preds == i) & (Y == i))\n",
    "                total[cls] += torch.sum(Y==i)\n",
    "\n",
    "    return {cls:correct[cls]/total[cls] for cls in classes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "078ff942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cabbagepatch/miniconda3/envs/new/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader = train.load_dataset(\"mnist-baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c03863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_masks(circuit_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59899954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12544, 12545, 12546,  ..., 43911, 43912, 43913])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_neurons(circuit_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb2ab765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: tensor(0.),\n",
       " 1: tensor(0.),\n",
       " 2: tensor(1.),\n",
       " 3: tensor(0.),\n",
       " 4: tensor(0.),\n",
       " 5: tensor(0.),\n",
       " 6: tensor(0.),\n",
       " 7: tensor(0.),\n",
       " 8: tensor(0.),\n",
       " 9: tensor(0.)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_wise_acc(circuit_1, testloader, [0,1,2,3,4,5,6,7,8,9], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ab417501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1154, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 28, 28)\n",
    "circuit_0(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "69a63333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for mask in circuit_0.masks:\n",
    "    print(mask.l0_loss())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69bb3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# X, Y = next(iter(testloader))\n",
    "# idx = 3\n",
    "# plt.imshow(X[idx].squeeze())\n",
    "# print(Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "961833cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def de(model, loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X,Y in loader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            logits = model(X)\n",
    "        \n",
    "            correct += torch.sum(logits.argmax(dim=1) == Y).item()\n",
    "            total += len(Y)\n",
    "    print(correct)\n",
    "    print(total)\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "\n",
    "x = torch.randn(1, *inp_shape)\n",
    "# for mask, module in zip(circuit_0.masks, circuit_0.model.chain):\n",
    "#     # print(mask)\n",
    "#     x = mask(module(x))\n",
    "#     print(x)\n",
    "testloader, trainloader = train.load_dataset(\"mnist-circuit-0\")\n",
    "de(circuit_0, trainloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d7050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dead(model: torch.nn.Module, inp_shape: list[int]):\n",
    "    dummy = torch.randn(inp_shape)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ec5350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ce.analyze_disconnected_unmasked(circuit_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ee6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_1 = run_class_circuit(1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c302a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_2 = run_class_circuit(2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ca215",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_3 = run_class_circuit(3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_4 = run_class_circuit(4, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_5 = run_class_circuit(5, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_6 = run_class_circuit(6, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ae594",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_7 = run_class_circuit(7, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbaa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_8 = run_class_circuit(8, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb572797",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_9 = run_class_circuit(9, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d0db91",
   "metadata": {},
   "source": [
    "### Finetuned layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a435f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 2: Train Sparse Baseline ---\n",
      "n_params 23628 n_params_wd 23568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cabbagepatch/miniconda3/envs/new/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n",
      "/home/cabbagepatch/miniconda3/envs/new/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Acc: 0.9357 | Test Acc: 0.9456\n",
      "Epoch 1 | Train Acc: 0.9511 | Test Acc: 0.9550\n",
      "Epoch 2 | Train Acc: 0.9436 | Test Acc: 0.9498\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Phase 2: Train Sparse Baseline ---\")\n",
    "train.finetune(\n",
    "    model=model,\n",
    "    num_classes=2,\n",
    "    lr=cfg['baseline']['lr'],\n",
    "    b1=0.9, b2=0.999,\n",
    "    ds_name=\"mnist-circuit\",\n",
    "    eps=1e-8,\n",
    "    epochs=cfg['baseline']['epochs'],\n",
    "    device=device,\n",
    "    seed=cfg['seed']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e648f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 3: Extract Circuit ---\n",
      "Calculating mean activations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cabbagepatch/miniconda3/envs/new/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n",
      "/home/cabbagepatch/miniconda3/envs/new/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Circuit...\n",
      "Extracting Circuit (L0 Lambda=0.0001)...\n",
      "Epoch 0 | Loss: 4.3552 | Avg Mask: -1.278 | Total Non-Zero: 2337.0 | | Circuit Acc: 0.0434\n",
      "Epoch 1 | Loss: 1.8895 | Avg Mask: -1.573 | Total Non-Zero: 1367.0 | | Circuit Acc: 0.5566\n",
      "Epoch 2 | Loss: 1.6700 | Avg Mask: -1.780 | Total Non-Zero: 1140.0 | | Circuit Acc: 0.5740\n",
      "Epoch 3 | Loss: 1.6140 | Avg Mask: -1.947 | Total Non-Zero: 971.0 | | Circuit Acc: 0.5545\n",
      "Epoch 4 | Loss: 1.5956 | Avg Mask: -2.092 | Total Non-Zero: 911.0 | | Circuit Acc: 0.5580\n",
      "Epoch 5 | Loss: 1.5883 | Avg Mask: -2.225 | Total Non-Zero: 867.0 | | Circuit Acc: 0.5582\n",
      "Epoch 6 | Loss: 1.5836 | Avg Mask: -2.351 | Total Non-Zero: 821.0 | | Circuit Acc: 0.5423\n",
      "Epoch 7 | Loss: 1.5765 | Avg Mask: -2.473 | Total Non-Zero: 773.0 | | Circuit Acc: 0.5486\n",
      "Epoch 8 | Loss: 1.5830 | Avg Mask: -2.591 | Total Non-Zero: 755.0 | | Circuit Acc: 0.5336\n",
      "Epoch 9 | Loss: 1.5876 | Avg Mask: -2.707 | Total Non-Zero: 740.0 | | Circuit Acc: 0.5346\n",
      "Epoch 10 | Loss: 1.5878 | Avg Mask: -2.821 | Total Non-Zero: 730.0 | | Circuit Acc: 0.5358\n",
      "Epoch 11 | Loss: 1.5866 | Avg Mask: -2.931 | Total Non-Zero: 731.0 | | Circuit Acc: 0.5337\n",
      "Epoch 12 | Loss: 1.5865 | Avg Mask: -3.039 | Total Non-Zero: 734.0 | | Circuit Acc: 0.5525\n",
      "Epoch 13 | Loss: 1.5861 | Avg Mask: -3.143 | Total Non-Zero: 727.0 | | Circuit Acc: 0.5328\n",
      "Epoch 14 | Loss: 1.5856 | Avg Mask: -3.241 | Total Non-Zero: 726.0 | | Circuit Acc: 0.5344\n",
      "Epoch 15 | Loss: 1.5863 | Avg Mask: -3.333 | Total Non-Zero: 725.0 | | Circuit Acc: 0.5328\n",
      "Epoch 16 | Loss: 1.5857 | Avg Mask: -3.417 | Total Non-Zero: 729.0 | | Circuit Acc: 0.5335\n",
      "Epoch 17 | Loss: 1.5860 | Avg Mask: -3.493 | Total Non-Zero: 726.0 | | Circuit Acc: 0.5347\n",
      "Epoch 18 | Loss: 1.5858 | Avg Mask: -3.561 | Total Non-Zero: 726.0 | | Circuit Acc: 0.5502\n",
      "Epoch 19 | Loss: 1.5856 | Avg Mask: -3.620 | Total Non-Zero: 723.0 | | Circuit Acc: 0.5533\n"
     ]
    }
   ],
   "source": [
    "# 3. Extract Circuit\n",
    "print(\"\\n--- Phase 3: Extract Circuit ---\")\n",
    "# Note: We pass the *trained* model to the circuit extractor\n",
    "cfg['circuit']['l0_lambda'] = 0.0001\n",
    "cfg['circuit']['lr'] = 1e-2\n",
    "cfg['circuit']['epochs'] = 20\n",
    "circuit = train.extract_circuit(\n",
    "    model=model,\n",
    "    lr=cfg['circuit']['lr'],\n",
    "    b1=0.9, b2=0.999,\n",
    "    ds_name=\"mnist-circuit\",\n",
    "    eps=1e-8,\n",
    "    epochs=cfg['circuit']['epochs'],\n",
    "    device=device,\n",
    "    l0_lambda=cfg['circuit']['l0_lambda'],\n",
    "    seed=cfg['seed']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "93149392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0003, 0.0006, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0006, 0.0000, 0.0003, 0.0000,\n",
       "         0.0000, 0.0000, 0.0003, 0.0003, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0003, 0.0000, 0.0013, 0.0010, 0.0003, 0.0006, 0.0006,\n",
       "         0.0000, 0.0000, 0.0003, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0016, 0.0022, 0.0013, 0.0016, 0.0000,\n",
       "         0.0003, 0.0003, 0.0006, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0003, 0.0010, 0.0019, 0.0016, 0.0010, 0.0003,\n",
       "         0.0000, 0.0000, 0.0006, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0006, 0.0010, 0.0013, 0.0013, 0.0013, 0.0003, 0.0000,\n",
       "         0.0000, 0.0000, 0.0003, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0010, 0.0010, 0.0010, 0.0006, 0.0003, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0003, 0.0006, 0.0019, 0.0006, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0003, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0006, 0.0006, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0003, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = circuit.masks[-6].mask.data\n",
    "\n",
    "sum(x > 0) / x.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd06932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
